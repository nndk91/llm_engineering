{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d5686-4e76-4110-b65a-b3906c35c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create your prompts\n",
    "import requests\n",
    "import ollama\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "#create message\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "     \"\"\"\n",
    "     How to fix error 403 in scrapping a website\n",
    "     \n",
    "   \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#print the result\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d98a55-03c9-4018-8200-b1d8793745d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khoa-Mac-PC\\anaconda3\\envs\\llms\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'doanhnghiep.biz'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dưới đây là nội dung của 2 trang brochure cho công ty CÔNG TY TNHH VSSC STEEL CENTER:\n",
      "\n",
      "**Trang 1**\n",
      "\n",
      "[ Hình ảnh công ty ]\n",
      "\n",
      "Công Ty TNHH VSSC Steel Center\n",
      "\n",
      "Một trong những nhà sản xuất hàng đầu về gia công cơ khí và xử lý kim loại tại Việt Nam\n",
      "\n",
      "**Giới thiệu**\n",
      "\n",
      "Công ty CÔNG TY TNHH VSSC STEEL CENTER được thành lập vào ngày 22/02/2021 với mục tiêu là trở thành một trong những nhà cung cấp hàng đầu về các sản phẩm cơ khí và xử lý kim loại tại Việt Nam. Chúng tôi cam kết mang đến cho khách hàng chất lượng tốt nhất và dịch vụ khách quan.\n",
      "\n",
      "**Ngành nghề**\n",
      "\n",
      "* Gia công cơ khí\n",
      "* Xử lý và tráng phủ kim loại\n",
      "* Bán buôn kim loại và quặng kim loại\n",
      "\n",
      "**Sản phẩm**\n",
      "\n",
      "Chúng tôi cung cấp các sản phẩm sau:\n",
      "\n",
      "* Cơ khí: cọc thép, thanh thép, dây thép, v.v.\n",
      "* Xử lý kim loại: xử lý bề mặt, xử lý nhiệt, v.v.\n",
      "* Kim loại và quặng kim loại: bán buôn và cung ứng\n",
      "\n",
      "**Địa chỉ**\n",
      "\n",
      "Đường N7 Khu Công Nghiệp Phú Mỹ Ii, Phường Tân Phước, Thị Xã Phú Mỹ, Bà Rịa - Vũng Tàu\n",
      "\n",
      "**Số điện thoại**\n",
      "\n",
      "0254 3503 001\n",
      "\n",
      "**Trang 2**\n",
      "\n",
      "[ Hình ảnh công ty ]\n",
      "\n",
      "Lên tiếng với chúng tôi!\n",
      "\n",
      "Chúng tôi cam kết mang đến cho khách hàng chất lượng tốt nhất và dịch vụ khách quan. Chúng tôi luôn sẵn sàng để phục vụ bạn.\n",
      "\n",
      "**Dịch vụ**\n",
      "\n",
      "* Gia công cơ khí\n",
      "* Xử lý và tráng phủ kim loại\n",
      "* Bán buôn kim loại và quặng kim loại\n",
      "* Cung ứng và bán buôn\n",
      "\n",
      "**Chính sách khách hàng**\n",
      "\n",
      "* Chúng tôi cam kết đáp ứng nhu cầu của khách hàng.\n",
      "* Chúng tôi luôn sẵn sàng để hỗ trợ bạn.\n",
      "* Chúng tôi đảm bảo chất lượng sản phẩm.\n",
      "\n",
      "**Hình ảnh công ty**\n",
      "\n",
      "[ Hình ảnh công ty ]\n",
      "\n",
      "Công Ty TNHH VSSC Steel Center - Một trong những nhà sản xuất hàng đầu về gia công cơ khí và xử lý kim loại tại Việt Nam.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers, verify=False)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "URL = Website(\"https://doanhnghiep.biz/3502447502\")\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the header of the website including the Name of the company {website.title} - \"\n",
    "    user_prompt += \"please find all the relevant information about this company. Including name, address, Tax ID, Phone Number, legal rep, business type.\"\n",
    "    user_prompt += \"No need for the list of relevant companies\\n\"\n",
    "    user_prompt += f\" {website.text}\"\n",
    "    return user_prompt\n",
    "\n",
    "REQUEST1 = get_links_user_prompt(URL)\n",
    "messages1 = [{\"role\": \"user\", \"content\": REQUEST1}]\n",
    "payload1 = {\"model\": MODEL, \"messages\": messages1, \"stream\": False}\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload1, headers=HEADERS)\n",
    "#print(response.json()['message']['content'])\n",
    "def Making_brochure(brochure):\n",
    "    user_prompt = f\"Here is the company profile {brochure} - \"\n",
    "    user_prompt += \"Please make a 2 page brochure for the company. \\n\"\n",
    "    return user_prompt\n",
    "\n",
    "REQUEST2 = Making_brochure(response.json()['message']['content'])\n",
    "messages2 = [ {\"role\": \"user\", \"content\": REQUEST2} ]\n",
    "payload2 = {\"model\": MODEL, \"messages\": messages2, \"stream\": False}\n",
    "response2 = requests.post(OLLAMA_API, json=payload2, headers=HEADERS)\n",
    "print(response2.json()['message']['content'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9193dc-64f5-417f-9cd6-79e2c4580c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "     create a python program to adding website + TaxID   \n",
    "I have a list of TaxID as below     \n",
    "List TaxID = 5300829397, 5300773641\n",
    "\n",
    "The website is https://doanhnghiep.biz/\n",
    "\n",
    "Example result is added to url list\n",
    "https://doanhnghiep.biz/3502447502\n",
    "https://doanhnghiep.biz/030352220\n",
    "     \"\"\"\n",
    "\n",
    "\n",
    "# Define the base URL and list of TaxIDs\n",
    "base_url = \"https://doanhnghiep.biz/\"\n",
    "tax_ids = [\"3502447502\", \"030352220\"]\n",
    "\n",
    "# Create an empty list to store the updated URLs\n",
    "updated_urls = []\n",
    "\n",
    "# Iterate over each TaxID and update the URL\n",
    "for tax_id in tax_ids:\n",
    "    updated_url = base_url + str(tax_id)\n",
    "    updated_urls.append(updated_url)\n",
    "\n",
    "# Print the updated URLs\n",
    "print(\"Updated URLs:\")\n",
    "for url in updated_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa9905-dbce-4ffc-a425-5164bef2d280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
